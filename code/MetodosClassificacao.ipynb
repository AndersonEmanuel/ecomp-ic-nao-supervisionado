{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MetodosClassificacao.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"xq14W7PLm96C"},"source":["from collections import Counter\n","import itertools\n","import sys\n","\n","#Parametros de suporte e confianca\n","s = 0.6\n","c = 0.6\n","\n","#Conjunto de transacoes\n","transacoes = {  1: {\"Cerveja\", \"Amendoim\", \"Laranja\"},\n","        2: {\"Cerveja\", \"Cafe\", \"Laranja\", \"Amendoim\"},\n","        3: {\"Cerveja\", \"Laranja\", \"Ovos\"},\n","        4: {\"Cerveja\", \"Amendoim\", \"Ovos\", \"Leite\"},\n","        5: {\"Cafe\", \"Laranja\", \"Ovos\", \"Leite\"},\n","        6: {\"Cafe\", \"Laranja\", \"Ovos\", \"Leite\"},\n","        7: {\"Laranja\", \"Cafe\", \"Cerveja\", \"Ovos\"},\n","        8: {\"Amendoim\", \"Cafe\", \"Cerveja\", \"Ovos\"},\n","        9: {\"Amendoim\", \"Laranja\", \"Cerveja\", \"Ovos\"},\n","        10: {\"Amendoim\", \"Cafe\", \"Cerveja\", \"Ovos\"}\n","        }\n","\n","#Faz a leitura do dicionario de transacoes\n","#Armazena cada item no vetor items\n","items = [] \n","for itemsets in transacoes.values():\n","    for item in itemsets:\n","        items.append(item)\n","items = set(items)\n","\n","### Cria as regras de associacao ##############################\n","def frequentItems(items, trans, n, s):\n","    itemsets = set(itertools.combinations(items, n))\n","\n","    itemTransactions = []\n","    for i in itemsets:\n","        for k,v in transacoes.items():\n","            if set(v).intersection(set(i)) == set(i):\n","                itemTransactions.append(i)\n","\n","    ret = []\n","    for k,v in sorted(Counter(itemTransactions).items()):\n","        if v >= s * len(trans):\n","            ret.append([k, v])\n","    return(dict(ret))\n","###############################################################\n","\n","#Mostra os resultados\n","print(\"1-itemsets mais frequentes:\")\n","print(frequentItems(items, transacoes, 1, s))\n","print\n","\n","print(\"2-itemsets mais frequentes:\")\n","print(frequentItems(items, transacoes, 2, s))\n","print\n","\n","print(\"3-itemsets mais frequentes:\")\n","print(frequentItems(items, transacoes, 3, s))\n","print\n","\n","#Imprime as regras de associacao\n","#De acordo com o suporte e confianca\n","print(\"Regras de associacao com suporte\")\n","print(\"e confianca maiores que 50%\")\n","f2 = frequentItems(items, transacoes, 2, s)\n","k2 = [k for k in f2.keys()]\n","v2 = [v for v in f2.values()]\n","\n","f1 = frequentItems(items, transacoes, 1, s)\n","k1 = [k[0] for k in f1.keys()]\n","v1 = [v    for v in f1.values()]\n","\n","for i in range(len(k2)):\n","    i1 = k2[i][0]\n","    i2 = k2[i][1]\n","    for j in range(len(k1)):\n","        if k1[j] == i1:\n","            confidence = v2[i]/v1[j]\n","    if v2[i] >= s * len(transacoes) and confidence >= c:\n","        print(\"{0:<6} -> {1:<6}: ({2},{3})\".format(i1, i2,str(v2[i]),confidence))\n","    \n","    i1 = k2[i][1]\n","    i2 = k2[i][0]\n","    for j in range(len(k1)):\n","        if k1[j] == i1:\n","            confidence = v2[i]/v1[j]\n","    if v2[i] >= s * len(transacoes) and confidence >= c:\n","        print(\"{0:<6} -> {1:<6}: ({2},{3})\".format(i1, i2,str(v2[i]),confidence))\n","        print"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XONlKzHXrJor","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596581523479,"user_tz":180,"elapsed":1658,"user":{"displayName":"Leandro Almeida","photoUrl":"","userId":"09469603528922348427"}},"outputId":"bb6cdf93-c58c-41d5-ec6a-7f0545bbab4d"},"source":["import numpy as np\n","from sklearn import datasets\n","from sklearn import tree\n","\n","# Load iris\n","iris = datasets.load_iris()\n","X = iris.data #inputs\n","y = iris.target #output\n","\n","# Constroi um classificador com arvore de decisao\n","dt = tree.DecisionTreeClassifier(criterion='entropy') #criando o objeto que Ã© a arvore\n","dt.fit(X, y) #<----\n","dotfile = open(\"dt-iris.dot\", 'w')\n","tree.export_graphviz(dt, out_file=dotfile, feature_names=iris.feature_names)\n","dotfile.close()\n","print(\"Arvore de decisao gerada no diretorio!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Arvore de decisao gerada no diretorio!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zMJOYWOjghJh"},"source":["import pandas\n","from sklearn.model_selection import train_test_split\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.preprocessing import LabelEncoder\n","\n","#definindo os nomes de cada coluna   \n","names = ['num-pregnant', 'glucose', 'diastolic', 'triceps-skin', 'insulin', 'body-mass', 'diabetes-pedigree', 'age', 'class']\n","\n","#Fazendo o carregamento dos dados diretamente do UCI Machine Learning          \n","dataset = pandas.read_csv(\"pima-indians-diabetes.csv\", names=names)\n","\n","print(\"Primeiros dados\")\n","print(dataset.head(5))\n","\n","#Convertendo dados categoricos para dados numericos\n","le = LabelEncoder()\n","for column_name in dataset.columns:\n","    if dataset[column_name].dtype == object:\n","        dataset[column_name] = pandas.Categorical(dataset[column_name]).codes()\n","        #dataset[column_name] = le.fit_transform(dataset[column_name])\n","    else:\n","        pass\n","\n","#divisao de dados atributos e classe\n","X = dataset.values[:, 0:7]\n","Y = dataset.values[:,8]\n","\n","#usando o metodo para fazer uma unica divisao dos dados\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 1)\n","\n","#criando diferentes RNAs\n","mlp1 = MLPClassifier(hidden_layer_sizes=([10]))\n","mlp2 = MLPClassifier(hidden_layer_sizes=(3,3),random_state=1)\n","mlp3 = MLPClassifier(hidden_layer_sizes=([5,5,2]))\n","\n","mlp1=mlp1.fit(X_train,y_train)\n","mlp2=mlp2.fit(X_train,y_train)\n","mlp3=mlp3.fit(X_train,y_train)\n","\n","print(\"Acuracia de trainamento MLP1: %0.3f\" %  mlp1.score(X_train, y_train))\n","print(\"Acuracia de teste MLP1: %0.3f\" %  mlp1.score(X_test, y_test))\n","\n","print(\"Acuracia de trainamento MLP2: %0.3f\" %  mlp2.score(X_train, y_train))\n","print(\"Acuracia de teste MLP2: %0.3f\" %  mlp2.score(X_test, y_test))\n","\n","print(\"Acuracia de trainamento MLP3 clf: %0.3f\" %  mlp3.score(X_train, y_train))\n","print(\"Acuracia de teste MLP3: %0.3f\" %  mlp3.score(X_test, y_test))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"th1iI1U103D1"},"source":["import pandas\n","from sklearn.model_selection import train_test_split\n","from sklearn import tree\n","from sklearn.preprocessing import LabelEncoder\n","\n","#definindo os nomes de cada coluna   \n","names = ['num-pregnant', 'glucose', 'diastolic', 'triceps-skin', 'insulin', 'body-mass', 'diabetes-pedigree', 'age', 'class']\n","\n","#Fazendo o carregamento dos dados diretamente do UCI Machine Learning          \n","dataset = pandas.read_csv(\"pima-indians-diabetes.csv\", names=names)\n","\n","print(\"Primeiros dados\")\n","print(dataset.head(5))\n","\n","#Convertendo dados categoricos para dados numericos\n","le = LabelEncoder()\n","for column_name in dataset.columns:\n","    if dataset[column_name].dtype == object:\n","        dataset[column_name] = le.fit_transform(dataset[column_name])\n","    else:\n","        pass\n","\n","#divisao de dados atributos e classe\n","X = dataset.values[:, 0:7] \n","Y = dataset.values[:,8]\n","\n","#usando o metodo para fazer uma unica divisao dos dados\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 10)\n","\n","#criando diferentes arvores\n","clf = tree.DecisionTreeClassifier(criterion='entropy',max_depth=10, random_state = 10)\n","clf2 = tree.DecisionTreeClassifier(max_depth=15,random_state = 10)\n","\n","clf = clf.fit(X_train, y_train) #treinamento\n","clf2 = clf2.fit(X_train, y_train) #treinamento\n","\n","print(\"Acuracia de trainamento clf: %0.3f\" %  clf.score(X_train, y_train))\n","print(\"Acuracia de teste clf: %0.3f\" %  clf.score(X_test, y_test))\n","\n","print(\"Acuracia de trainamento clf2: %0.3f\" %  clf2.score(X_train, y_train))\n","print(\"Acuracia de teste clf2: %0.3f\" %  clf2.score(X_test, y_test))\n","\n","print(\"Profundidade das arvores criadas\")\n","print(clf.tree_.max_depth)\n","print(clf2.tree_.max_depth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q76CYc0X7q_z"},"source":["import pandas\n","from sklearn.model_selection import train_test_split\n","from sklearn import neighbors\n","   \n","#definindo os nomes de cada coluna   \n","names = ['num-pregnant', 'glucose', 'diastolic', 'triceps-skin', 'insulin', 'body-mass', 'diabetes-pedigree', 'age', 'class']\n","\n","#Fazendo o carregamento dos dados diretamente do UCI Machine Learning          \n","dataset = pandas.read_csv(\"pima-indians-diabetes.csv\", names=names)\n","\n","print(\"Primeiros dados\")\n","print(dataset.head(5))\n","\n","#divisao de dados atributos e classe\n","X = dataset.values[:, 0:7]\n","Y = dataset.values[:,8]\n","\n","#usando o metodo para fazer uma unica divisao dos dados\n","X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.25, random_state = 10)\n","\n","# we create an instance of Neighbours Classifier and fit the data.\n","clf = neighbors.KNeighborsClassifier(7)\n","\n","clf = clf.fit(X_train, y_train)\n","\n","print(\"Acuracia de trainamento clf: %0.3f\" %  clf.score(X_train, y_train))\n","print(\"Acuracia de teste clf: %0.3f\" %  clf.score(X_test, y_test))\n"],"execution_count":null,"outputs":[]}]}